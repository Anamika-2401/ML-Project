{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1757945505082}],"collapsed_sections":["vncDsAP0Gaoa","x71ZqKXriCWQ","7hBIi_osiCS2","JlHwYmJAmNHm","35m5QtbWiB9F","PoPl-ycgm1ru","H0kj-8xxnORC","PBTbrJXOngz2","u3PMJOP6ngxN","MSa1f5Uengrz","0wOQAZs5pc--","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","KSlN3yHqYklG","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","EM7whBJCYoAo","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","4Of9eVA-YrdM","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","Yfr_Vlr8HBkt","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","T0VqWOYE6DLQ","qBMux9mC6MCf","pEMng2IbBLp7","rAdphbQ9Bhjc","yiiVWRdJDDil","T5CmagL3EC8N","qjKvONjwE8ra","VFOzZv6IFROw","TIqpNgepFxVj","PiV4Ypx8fxKe","TfvqoZmBfxKf","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","7AN1z2sKpx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    -  Rossmann Retail Sales Prediction\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Regression\n","##### **Contribution**    - Individual"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["Write the summary here within 500-600 words.\n","\n","Introduction\n","\n","Retail businesses generate a large volume of transactional data on a daily basis. Analyzing this data can provide deep insights into customer behavior, the effectiveness of promotions, the impact of holidays and overall store performance. The dataset under consideration captures sales information for multiple stores across different dates, along with contextual features such as day of the week, whether the store was open, promotional activities and holiday indicators. This project focuses on preparing, analyzing and modeling this dataset to forecast store sales and derive meaningful business insights.\n","\n","Dataset Overview\n","\n","The dataset contains the following key features:\n","\n","Store: Unique identifier for each retail store.\n","\n","DayOfWeek: Numeric representation of the day of the week.\n","\n","Date: Actual date of the transaction.\n","\n","Sales: Total sales revenue generated on the given date.\n","\n","Customers: Number of customers visiting the store.\n","\n","Open: Indicator showing whether the store was open or closed.\n","\n","Promo: Indicates whether a promotion was running on that day.\n","\n","StateHoliday: Represents whether the day was a state holiday.\n","\n","SchoolHoliday: Represents whether the day coincided with a school holiday.\n","\n","The dataset captures multiple dimensions of sales performance, making it suitable for both descriptive analysis and predictive modeling.\n","\n","Data Preprocessing and Cleaning\n","\n","Data preprocessing was an essential step to ensure the dataset was ready for analysis. The following actions were performed:\n","\n","Handling Missing Values: Any rows with incomplete data were checked and treated appropriately.\n","\n","Removing Irrelevant Data: Sales values equal to zero on days when stores were closed were removed, as they did not contribute meaningful information.\n","\n","Feature Engineering:\n","\n","Extracted Year, Month, Day, WeekOfYear and WeekdayName from the Date field to capture seasonality and temporal trends.\n","\n","Calculated Sales per Customer to normalize sales against customer count.\n","\n","Applied transformations (log, square root) on skewed variables such as Sales and Customers to stabilize variance.\n","\n","Outlier Detection: Outliers in Sales and Customer counts were identified and treated using statistical techniques.\n","\n","Exploratory Data Analysis (EDA)\n","\n","EDA was carried out to understand trends and relationships:\n","\n","Sales were observed to vary across weekdays, with weekends and promotional days showing higher sales.\n","\n","Promotions had a direct positive impact on sales, though the magnitude varied across stores.\n","\n","State and school holidays showed mixed effects — for some stores sales dropped, while for others they increased due to higher customer availability.\n","\n","Strong correlations were found between Sales and Customers, as expected.\n","\n","Model Development\n","\n","Several machine learning models were tested to predict Sales based on the available features:\n","\n","Linear Regression: Served as a baseline model but underperformed due to non-linear patterns in the data.\n","\n","Random Forest Regressor: Provided robust performance with high R² values and low error metrics, demonstrating the ability to capture non-linear interactions.\n","\n","XGBoost Regressor: Produced competitive results but required careful hyperparameter tuning.\n","\n","Hyperparameter optimization techniques such as GridSearchCV and RandomizedSearchCV were employed to fine-tune model parameters, ensuring better generalization. Cross-validation was used to reduce overfitting and provide realistic performance estimates.\n","\n","Model Evaluation\n","\n","Evaluation was performed using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R², Adjusted R² and Mean Absolute Percentage Error (MAPE).\n","\n","Random Forest achieved an R² above 0.99 during initial runs, later stabilizing at ~0.99 with cross-validation.\n","\n","MAPE values around 12–15% indicated reasonably accurate forecasts.\n","\n","XGBoost delivered slightly lower R² (~0.78) but can be further improved with parameter tuning.\n","\n","Insights and Business Impact\n","\n","The analysis provides valuable insights for retail decision-making:\n","\n","Promotions are a strong driver of sales, but effectiveness varies across stores.\n","\n","Seasonality and holidays play a critical role and should be incorporated into forecasting models.\n","\n","Customer counts are highly predictive of sales, suggesting that increasing footfall directly impacts revenue.\n","\n","Predictive models developed here can help in sales forecasting, inventory planning, staffing decisions and promotional planning.\n","\n","Conclusion\n","\n","This project demonstrates how structured retail sales data can be leveraged for predictive modeling. Through preprocessing, feature engineering, exploratory analysis and model implementation, we developed accurate forecasting models. Random Forest emerged as the best-performing model, providing strong predictive power. The insights derived are actionable for retail businesses to optimize operations, improve sales and make data-driven strategic decisions."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here."],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["**Write Problem Statement Here.**\n","\n","The goal of this project is to:\n","\n","1. Preprocess and clean the dataset to handle missing values, outliers and irrelevant records.\n","\n","2. Perform exploratory data analysis (EDA) to uncover patterns and relationships among sales drivers.\n","\n","3. Develop and evaluate predictive models (Linear Regression, Random Forest, XGBoost, etc.) using appropriate performance metrics.\n","\n","4. Optimize model performance through hyperparameter tuning techniques such as GridSearchCV, RandomizedSearchCV and Bayesian Optimization.\n","\n","5. Provide actionable insights that can help businesses improve sales forecasting, optimize resource allocation and design effective promotional campaigns."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data=pd.read_csv('/content/drive/MyDrive/Rossmann Stores Data.csv')\n","data"],"metadata":{"id":"3_wn21U4vzpO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","data.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","data.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","data.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","data.duplicated().sum()\n"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","data.isnull().sum()"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import missingno as msno\n","\n","# bar plot of missing values\n","msno.bar(data)"],"metadata":{"id":"ZPGlKYLcMDMS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["Answer Here\n","\n","1. In data.head() we get first 5 rows.\n","2. In data.tail() we get last 5 rows.\n","3. In the given data we have 1017209 rows and 10 columns.\n","4. Data types of given data is int64(3), object(7).\n","5. Memory usages is 77.6+ MB MB.\n","6. No duplicate data is present.\n","7. No missing values are present."],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","data.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Only numerical columns\n","num_data=data.select_dtypes(include=['int64','float64'])\n","num_data"],"metadata":{"id":"XfNtPM-2OeZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Only categorical columns\n","cal_data=data.select_dtypes(include=['object'])\n","cal_data"],"metadata":{"id":"8vFdVG4IOhUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","data.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["Answer Here\n","\n","1.Store\t- Store id\n","\n","2.DayOfWeek\t- Day of the week\n","\n","3.Date - Date of sale\n","\n","4.Sales\t- Sale made for the day\n","\n","5.Customers\t- Customer for the day\n","\n","6.Open - Store is open or closed\n","\n","7.Promo\t- Store running promotion or not\n","\n","8.StateHoliday - State holiday or not\n","\n","9.SchoolHoliday\t- School holiday or not\n","\n"],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","data.nunique()"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#New columns Year,month,WeekOfYear and day\n","data[\"Year\"] = data[\"Date\"].dt.year\n","data[\"Month\"] = data[\"Date\"].dt.month\n","data[\"Day\"] = data[\"Date\"].dt.day\n","data[\"WeekOfYear\"] = data[\"Date\"].dt.isocalendar().week\n"],"metadata":{"id":"0vGCmPSVSmrL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Week day name\n","data[\"WeekdayName\"] = data[\"Date\"].dt.day_name()\n"],"metadata":{"id":"tKawjuQ3Wd1E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Sales per customer\n","data[\"SalesPerCustomer\"] = data[\"Sales\"] / data[\"Customers\"]\n","data[\"SalesPerCustomer\"] = data[\"SalesPerCustomer\"].fillna(0)"],"metadata":{"id":"QFewxOD1UUAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Sales and customer must be more then zero\n","data= data[data[\"Sales\"] >= 0]\n","data = data[data[\"Customers\"] >= 0]\n"],"metadata":{"id":"cE3Ssct2Uh-G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Avg sales according to year\n","data.groupby([\"Year\"])[\"Sales\"].mean()"],"metadata":{"id":"3u3bhO9GU5VL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Avg sales of weekdayname\n","data.groupby([\"WeekdayName\"])[\"Sales\"].mean()"],"metadata":{"id":"GuBEsbs-Vzf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"yWz99If2W7ZL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Converted date into datetime datatype and then we have got new columns like year, month, day, weekdayname and salepercustomer.\n","\n","We have find the the average sales according to year and weekdayname."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","plt.figure()\n","sns.histplot(data[\"Sales\"], bins=50, kde=False)\n","plt.title(\"Sales distribution\")\n","plt.xlabel(\"Sales\")\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I have chosen a histogram because it is the most effective chart to visualize the frequency distribution of a continuous variable like Sales."],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["Answer Here\n","\n","The majority of sales values are concentrated within a lower to mid-range, showing that most stores on most days generate moderate revenue.\n","\n","There is a noticeable right-skewness in the distribution, indicating that while high sales days exist, they are relatively rare compared to low and medium sales days.\n","\n","Few extreme values (potential outliers) are present at the higher end, which might be due to special events, holidays or promotions."],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Understanding that most sales cluster in a moderate range helps businesses forecast more accurately and allocate resources efficiently.\n","\n","Identifying occasional high sales spikes can guide businesses to analyze the factors behind those peaks and replicate such strategies.\n","\n","yes, If most stores consistently remain in the low-to-mid sales range, it could signal limited customer engagement or ineffective promotional strategies."],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","plt.figure()\n","sns.histplot(data[\"Customers\"], bins=80, kde=False)\n","plt.title(\"Customers distribution\")\n","plt.xlabel(\"Customers\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A histogram was selected because it is ideal for visualizing the distribution of a continuous variable like the number of Customers visiting the stores."],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["Answer Here\n","\n","The distribution shows that most stores receive a moderate number of customers per day, with fewer instances of extremely high customer counts.\n","\n","There may be a right-skewness, meaning that while some stores occasionally attract a large crowd, those cases are less frequent compared to normal or low-traffic days."],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["Answer Here\n","\n","By identifying typical customer ranges, businesses can optimize staffing levels, ensuring enough employees are present on high-traffic days while avoiding overstaffing on low-traffic days.\n","\n","Understanding peak customer behavior (on weekends, promotions, or holidays) helps in planning marketing campaigns, promotions and inventory management.\n","\n","yes, If too many stores fall into the low-customer range, it signals weak store performance, poor location appeal or lack of promotional effectiveness, which may harm long-term growth."],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","plt.figure()\n","sns.scatterplot(x=\"Customers\", y=\"Sales\", data=data, alpha=0.25)\n","plt.title(\" Sales vs Customers (sample)\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A scatter plot is the most effective chart when exploring the relationship between two continuous variables—in this case, Customers (x-axis) and Sales (y-axis)."],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Here is a positive correlation between Customers and Sales: generally, as the number of customers increases, sales also rise.\n","\n","However, the relationship is not perfectly linear—there are points where a high number of customers does not necessarily translate into proportionally higher sales, which could indicate:\n","\n","Customers visiting without making significant purchases.\n","\n","Store or stock limitations.\n","\n","Impact of promotions where many visitors come but buy discounted/low-value items."],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["Answer Here\n","\n","This analysis helps confirm that driving customer traffic generally increases sales, supporting investments in promotions, advertisements and loyalty programs.\n","\n","Identifying cases where sales are disproportionately low despite high customers allows managers to investigate product mix, pricing or store layout issues.\n","\n","Yes, If sales do not scale well with customer numbers, it indicates inefficient conversion rates (customers visiting but not buying), which is a warning sign for revenue leakage."],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["#### Chart - 4"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","daily = data.groupby(\"Year\")[\"Sales\"].sum().reset_index()\n","plt.figure(figsize=(14,4))\n","plt.plot(daily[\"Year\"], daily[\"Sales\"])\n","plt.title(\"sales over year\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Total Sales\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A line chart is best suited for analyzing trends over time. Since the data represents yearly aggregated sales, a line plot makes it easy to observe how sales evolve across years."],"metadata":{"id":"aJRCwT6DYrdO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"F6T5p64dYrdO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Sale is decreasing with time in 2013 but there is drastic change in sale in 2014, sales are declining, raising concern about customer retention or competition."],"metadata":{"id":"Xx8WAJvtYrdO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"y-Ehk30pYrdP"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Understanding sales trends helps management make data-driven strategic decisions (e.g., whether to scale operations, invest in marketing, or optimize staffing).\n","\n","Identifying growth years helps replicate successful strategies (promotions, product launches).\n","\n","Yes, A declining trend may highlight loss of market share, customer dissatisfaction or rising competition—requiring corrective measures."],"metadata":{"id":"jLNxxz7MYrdP"}},{"cell_type":"markdown","source":["#### Chart - 5"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","monthly = data.groupby([\"Year\",\"Month\"])[\"Sales\"].sum().reset_index()\n","monthly[\"YearMonth\"] = pd.to_datetime(monthly.assign(day=1)[[\"Year\",\"Month\",\"day\"]])\n","plt.figure(figsize=(12,4))\n","plt.plot(monthly[\"YearMonth\"], monthly[\"Sales\"], marker='o')\n","plt.title(\"Monthly total sales\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"QHF8YVU7Yuh3"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A line chart with time on the x-axis is ideal for showing monthly sales trends because:\n","\n","It highlights seasonality and recurring patterns.\n","\n","It captures short-term fluctuations that yearly sales charts might miss.\n","\n","The markers ('o') help identify exact months where sales peaked or dropped, making the chart more interpretable for business decisions."],"metadata":{"id":"dcxuIMRPYuh3"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":["Answer Here\n","\n","We can see regular ups and downs suggest that seasonality plays a major role in customer purchasing behavior."],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"qYpmQ266Yuh3"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Detecting high-sales months allows businesses to prepare for demand by stocking inventory, increasing staff and launching targeted promotions.\n","\n","Identifying low-sales months enables managers to plan special discounts or marketing campaigns to stabilize revenue.\n","\n","Yes, Declining sales in successive months may point to weakening demand or ineffective promotions."],"metadata":{"id":"_WtzZ_hCYuh4"}},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"code","source":["# Chart - 6 visualization code\n","order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n","plt.figure()\n","sns.boxplot(x=\"WeekdayName\", y=\"Sales\", data=data, order=order)\n","plt.title(\"Sales distribution by weekday\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"bbFf2-_FphqN"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A boxplot is best suited here because it shows:\n","\n","The distribution of sales values across each day of the week.\n","\n","Median sales performance for each weekday.\n","\n","The spread/variability of sales, along with outliers.\n","\n","Unlike bar charts (which only show averages), boxplots provide a deeper understanding of variability and unusual sales behaviors for different weekdays."],"metadata":{"id":"loh7H2nzphqN"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"_ouA3fa0phqN"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Here we can see Monday show higher medians and wider spreads, reflecting greater customer turnout."],"metadata":{"id":"VECbqPI7phqN"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"Seke61FWphqN"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Helps in staff scheduling: Allocate more employees on high-sales days (e.g., weekends) to handle demand efficiently.\n","\n","Marketing campaigns can be targeted on slower weekdays to boost footfall and sales."],"metadata":{"id":"DW4_bGpfphqN"}},{"cell_type":"markdown","source":["#### Chart - 7"],"metadata":{"id":"PIIx-8_IphqN"}},{"cell_type":"code","source":["# Chart - 7 visualization code\n","avg_weekday = data.groupby(\"WeekdayName\")[\"Sales\"].mean().reindex(order)\n","plt.figure()\n","avg_weekday.plot(kind=\"bar\")\n","plt.title(\"Average Sales by Weekday\")\n","plt.ylabel(\"Average Sales\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"lqAIGUfyphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t27r6nlMphqO"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A bar chart is ideal for comparing categorical variables (weekdays) against a numerical measure (average sales)."],"metadata":{"id":"iv6ro40sphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"r2jJGEOYphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Certain days (likely Sunday, Saturday) show lower average sales, indicating weaker store activity.\n","\n","Other days (such as Monday or Tuesday) reflect higher averages, suggesting high demand in weekdays."],"metadata":{"id":"Po6ZPi4hphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"b0JNsNcRphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Helps in resource optimization: stores can stock more inventory and assign more staff on high-sales days.\n","\n","Targeted discounts or promotions can be planned on low-sales weekdays to boost revenue."],"metadata":{"id":"xvSq8iUTphqO"}},{"cell_type":"markdown","source":["#### Chart - 8"],"metadata":{"id":"BZR9WyysphqO"}},{"cell_type":"code","source":["# Chart - 8 visualization code\n","plt.figure()\n","sns.boxplot(x=\"Promo\", y=\"Sales\", data=data)\n","plt.title(\"Sales distribution: Promo vs No Promo\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"TdPTWpAVphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"jj7wYXLtphqO"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A boxplot is best suited here because it allows comparison of sales distributions between two groups: days with promotions and days without.\n","\n","It shows median sales, variability and outliers, helping us understand how promotions actually affect sales."],"metadata":{"id":"Ob8u6rCTphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"eZrbJ2SmphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","A boxplot is best suited here because it allows comparison of sales distributions between two groups: days with promotions and days without.\n","\n","It shows median sales, variability and outliers, helping us understand how promotions actually affect sales.\n","Outliers on promo days indicate that certain promotions were extremely successful, leading to unusually high sales."],"metadata":{"id":"mZtgC_hjphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"rFu4xreNphqO"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Confirms that promotions are an effective strategy to boost sales performance.\n","\n","Insights can guide businesses to optimize promotional frequency and timing (e.g., aligning with weekends or holidays)."],"metadata":{"id":"ey_0qi68phqO"}},{"cell_type":"markdown","source":["#### Chart - 9"],"metadata":{"id":"YJ55k-q6phqO"}},{"cell_type":"code","source":["# Chart - 9 visualization code\n","plt.figure()\n","sns.boxplot(x=\"StateHoliday\", y=\"Sales\", data=data)\n","plt.title(\"Sales by StateHoliday\")\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"B2aS4O1ophqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"gCFgpxoyphqP"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","A boxplot is ideal for comparing sales distributions across different categories of state holidays (e.g., no holiday, public holiday, Easter, Christmas).\n","\n","It shows median sales, spread and outliers, giving a complete picture of how holidays affect store performance."],"metadata":{"id":"TVxDimi2phqP"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"OVtJsKN_phqQ"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Sales behavior is significantly different on holidays compared to regular days.\n","\n","Some holidays (like Christmas or Easter) show higher sales spikes due to festive shopping."],"metadata":{"id":"ngGi97qjphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"lssrdh5qphqQ"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Businesses can plan special promotions and stock more inventory for high-demand holidays to maximize revenue.\n","\n","Helps in staff allocation: more employees can be scheduled during peak holiday shopping."],"metadata":{"id":"tBpY5ekJphqQ"}},{"cell_type":"markdown","source":["#### Chart - 10"],"metadata":{"id":"U2RJ9gkRphqQ"}},{"cell_type":"code","source":["# Chart - 10 visualization code\n","plt.figure()\n","sns.boxplot(x=\"Open\", y=\"Sales\", data=data)\n","plt.title(\"Sales when Open vs Closed\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"GM7a4YP4phqQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"1M8mcRywphqQ"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","The boxplot is ideal here because it compares the distribution of Sales between two categories of the Open column (1 = Open, 0 = Closed)."],"metadata":{"id":"8agQvks0phqQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"tgIPom80phqQ"}},{"cell_type":"markdown","source":["Answer Here\n","\n","All rows shown have Open = 1, so the boxplot would show higher sales for open stores. Closed stores (Open = 0) would likely show very low or zero sales.\n","\n","Median and spread of sales are much higher when stores are open."],"metadata":{"id":"Qp13pnNzphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"JMzcOPDDphqR"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Ensuring stores are open maximizes revenue potential. Promotions can be targeted on open days to further boost sales."],"metadata":{"id":"R4Ka1PC2phqR"}},{"cell_type":"markdown","source":["#### Chart - 11"],"metadata":{"id":"x-EpHcCOp1ci"}},{"cell_type":"code","source":["month_sale=data.groupby([\"Month\"])[\"Sales\"].mean().reset_index()\n","plt.figure(figsize=(12,4))\n","plt.plot(month_sale[\"Month\"], month_sale[\"Sales\"], marker='o')\n","plt.ylabel(\"Sales\")\n","plt.xlabel(\"Month\")\n","plt.title(\"Monthly total sales\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"lO55GlK88uU3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"X_VqEhTip1ck"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I chose a line chart because it is the best way to show trends over time. Since months are sequential, a line plot makes it easy to observe upward or downward patterns in sales across different months"],"metadata":{"id":"-vsMzt_np1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"8zGJKyg5p1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Sales vary across months, showing seasonal trends (peaks in certain months and dips in others).\n","Some months consistently outperform others, indicating potential high-demand seasons."],"metadata":{"id":"ZYdMsrqVp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"PVzmfK_Ep1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Understanding monthly sales trends helps in demand forecasting, inventory planning, staffing and marketing campaigns."],"metadata":{"id":"druuKYZpp1ck"}},{"cell_type":"markdown","source":["#### Chart - 12"],"metadata":{"id":"n3dbpmDWp1ck"}},{"cell_type":"code","source":["# Chart - 12 visualization code\n","plt.figure()\n","sns.histplot(data[\"SalesPerCustomer\"].replace([np.inf, -np.inf], np.nan).dropna(), bins=80, kde=True)\n","plt.title(\"SalesPerCustomer distribution\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"bwevp1tKp1ck"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"ylSl6qgtp1ck"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I chose a histogram with KDE (Kernel Density Estimation) because it is the most effective way to understand the distribution of a continuous variable like SalesPerCustomer."],"metadata":{"id":"m2xqNkiQp1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ZWILFDl5p1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","The distribution may be right-skewed, meaning most customers generate lower sales, but a few customers contribute very high sales.\n","\n","Majority of customers cluster around a typical spending range, which could be considered the average transaction value."],"metadata":{"id":"x-lUsV2mp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"M7G43BXep1ck"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Businesses can use this insight for customer segmentation—targeting high-value customers with loyalty programs while designing promotions to increase spending of low-value customers."],"metadata":{"id":"5wwDJXsLp1cl"}},{"cell_type":"markdown","source":["#### Chart - 13"],"metadata":{"id":"Ag9LCva-p1cl"}},{"cell_type":"code","source":["# Chart - 13 visualization code\n","open_zero = data[(data[\"Open\"]==1) & (data[\"Sales\"]==0)]\n","print(\"Open & Sales==0 count:\", len(open_zero))\n","# Visualize count by weekday\n","plt.figure()\n","open_zero.groupby(\"WeekdayName\").size().reindex(order).plot(kind=\"bar\")\n","plt.title(\"Count of rows where Open==1 but Sales==0 by weekday\")\n","plt.ylabel(\"Count\")\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"EUfxeq9-p1cl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"E6MkPsBcp1cl"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I chose a bar chart because it effectively compares the frequency of zero-sales days (while stores were open) across weekdays."],"metadata":{"id":"V22bRsFWp1cl"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"2cELzS2fp1cl"}},{"cell_type":"markdown","source":["Answer Here\n","\n","The plot shows that certain weekdays like thursday have a higher number of open stores with zero sales, which is unusual since open stores are expected to generate revenue.\n","\n"],"metadata":{"id":"ozQPc2_Ip1cl"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"3MPXvC8up1cl"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Identifying zero-sales days when stores are open helps in quality control and operational troubleshooting. Businesses can check if it’s due to staffing shortages, supply issues or system errors and fix them to avoid missed revenue."],"metadata":{"id":"GL8l1tdLp1cl"}},{"cell_type":"markdown","source":["#### Chart - 14 - Correlation Heatmap"],"metadata":{"id":"NC_X3p0fY2L0"}},{"cell_type":"code","source":["# Correlation Heatmap visualization code\n","num_cols = [\"Sales\", \"Customers\", \"Promo\", \"SchoolHoliday\", \"SalesPerCustomer\"]\n","corr = data[num_cols].corr()\n","plt.figure(figsize=(6,4))\n","sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\")\n","plt.title(\"Correlation heatmap\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"xyC9zolEZNRQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"UV0SzAkaZNRQ"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I chose a heatmap because it is the most effective way to visualize correlations between multiple numerical variables at once."],"metadata":{"id":"DVPuT8LYZNRQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"YPEH6qLeZNRQ"}},{"cell_type":"markdown","source":["Answer Here\n","\n","Sales and Customers show a strong positive correlation → more customers lead to higher sales.\n","\n","Promo and Sales may also show a positive correlation, indicating promotions help boost revenue.\n","\n","SchoolHoliday seems to have little or weak correlation with sales, suggesting holidays do not strongly impact sales behavior.\n","\n","SalesPerCustomer might be weakly correlated with the other variables, showing individual customer spending patterns are not directly tied to volume-based factors like customer count."],"metadata":{"id":"bfSqtnDqZNRR"}},{"cell_type":"markdown","source":["#### Chart - 15 - Pair Plot"],"metadata":{"id":"q29F0dvdveiT"}},{"cell_type":"code","source":["# Pair Plot visualization code\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Select numeric columns of interest\n","num_cols = [\"Sales\", \"Customers\", \"Promo\", \"SchoolHoliday\", \"SalesPerCustomer\"]\n","\n","# Sample a subset if dataset is huge (for faster plotting)\n","sample_data = data[num_cols].sample(5000, random_state=42)\n","\n","# Pair plot\n","sns.pairplot(sample_data, diag_kind=\"kde\", plot_kws={\"alpha\":0.3})\n","plt.suptitle(\"Pair Plot of Key Numeric Features\", y=1.02)\n","plt.show()\n"],"metadata":{"id":"o58-TEIhveiU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"EXh0U9oCveiU"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I chose a pair plot because it allows visualization of both distributions (diagonal plots) and pairwise relationships (scatterplots) among multiple numeric features in a single view."],"metadata":{"id":"eMmPjTByveiU"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"22aHeOlLveiV"}},{"cell_type":"markdown","source":["Answer Here\n","\n","A clear positive relationship exists between Sales and Customers → more customers lead to higher sales.\n","\n","The impact of Promo on Sales shows some scattered upward patterns, though not perfectly linear.\n","\n","SchoolHoliday mostly appears scattered without a strong visible relationship with Sales.\n","\n","The distributions show Sales and Customers are right-skewed, meaning most days have moderate values with occasional high spikes."],"metadata":{"id":"uPQ8RGwHveiV"}},{"cell_type":"markdown","source":["## ***5. Hypothesis Testing***"],"metadata":{"id":"g-ATYxFrGrvw"}},{"cell_type":"markdown","source":["### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."],"metadata":{"id":"Yfr_Vlr8HBkt"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"-7MS06SUHkB-"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 1"],"metadata":{"id":"8yEUt7NnHlrM"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"tEA2Xm5dHt1r"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","H0: mean(Sales | Promo = 1) = mean(Sales | Promo = 0)\n","\n","H1: mean(Sales | Promo = 1) > mean(Sales | Promo = 0) (one-sided)"],"metadata":{"id":"HI9ZP0laH0D-"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"I79__PHVH19G"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","import pandas as pd\n","import numpy as np\n","from scipy import stats\n","\n","# Assuming your data is in a DataFrame called data with columns \"Sales\" and \"Promo\"\n","\n","# Split Sales based on Promo ---\n","sales_promo = data[data[\"Promo\"] == 1][\"Sales\"]\n","sales_no_promo = data[data[\"Promo\"] == 0][\"Sales\"]\n","\n","# Descriptive statistics ---\n","mean_promo = sales_promo.mean()\n","mean_no_promo = sales_no_promo.mean()\n","std_promo = sales_promo.std()\n","std_no_promo = sales_no_promo.std()\n","\n","print(\"Mean Sales (Promo=1):\", mean_promo)\n","print(\"Mean Sales (Promo=0):\", mean_no_promo)\n","print(\"Std Dev (Promo=1):\", std_promo)\n","print(\"Std Dev (Promo=0):\", std_no_promo)\n","\n","\n","# Welch’s t-test (does not assume equal variances) ---\n","t_test = stats.ttest_ind(sales_promo, sales_no_promo, equal_var=False)\n","print(\"Welch’s t-test:\", t_test)\n","\n","# One-sided test (Promo > No Promo)\n","t_stat = t_test.statistic\n","p_one_sided = t_test.pvalue / 2 if t_stat > 0 else 1 - (t_test.pvalue / 2)\n","print(\"One-sided p-value (Promo > No Promo):\", p_one_sided)\n","\n","\n","\n"],"metadata":{"id":"oZrfquKtyian"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"Ou-I18pAyIpj"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Welch’s t-test (via stats.ttest_ind(..., equal_var=False)) → p-value for testing if the mean sales differ between Promo=1 and Promo=0.\n","\n","You also computed a one-sided p-value for testing specifically if Promo > No Promo."],"metadata":{"id":"s2U0kk00ygSB"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"fF3858GYyt-u"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Chosen because it is robust when variances are unequal and when sample sizes are very different.\n","\n","It tests whether mean sales differ between Promo=1 and Promo=0."],"metadata":{"id":"HO4K0gP5y3B4"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 2"],"metadata":{"id":"4_0_7-oCpUZd"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"hwyV_J3ipUZe"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","H0: mean(Sales | SchoolHoliday = 1) = mean(Sales | SchoolHoliday = 0)\n","\n","H1: means differ (two-sided)"],"metadata":{"id":"FnpLGJ-4pUZe"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"3yB-zSqbpUZe"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","import numpy as np\n","import pandas as pd\n","from scipy import stats\n","\n","# Assume your dataframe is named data with columns \"SchoolHoliday\" and \"Sales\"\n","\n","# Split data ---\n","sales_holiday = data[data[\"SchoolHoliday\"] == 1][\"Sales\"]\n","sales_no_holiday = data[data[\"SchoolHoliday\"] == 0][\"Sales\"]\n","\n","# Descriptive stats ---\n","n_holiday = len(sales_holiday)\n","n_no_holiday = len(sales_no_holiday)\n","mean_holiday = sales_holiday.mean()\n","mean_no_holiday = sales_no_holiday.mean()\n","sd_holiday = sales_holiday.std()\n","sd_no_holiday = sales_no_holiday.std()\n","\n","print(f\"n (SchoolHoliday=1) = {n_holiday}, mean = {mean_holiday:.2f}, sd = {sd_holiday:.2f}\")\n","print(f\"n (SchoolHoliday=0) = {n_no_holiday}, mean = {mean_no_holiday:.2f}, sd = {sd_no_holiday:.2f}\")\n","\n","# Levene’s Test for equal variances ---\n","levene_test = stats.levene(sales_holiday, sales_no_holiday)\n","print(\"Levene’s Test:\", levene_test)\n","\n"],"metadata":{"id":"sWxdNTXNpUZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"dEUvejAfpUZe"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Levene’s Test → p-value tests whether the variances of sales during holidays vs. non-holidays are equal."],"metadata":{"id":"oLDrPz7HpUZf"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"Fd15vwWVpUZf"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Levene’s Test was chosen to check if the assumption of equal variances holds, which informs whether a standard t-test is appropriate."],"metadata":{"id":"4xOGYyiBpUZf"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 3"],"metadata":{"id":"bn_IUdTipZyH"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"49K5P_iCpZyH"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","H0: mean(Sales | Saturday) = mean(Sales | Monday)\n","\n","H1: mean(Sat) > mean(Mon) (one-sided)"],"metadata":{"id":"7gWI5rT9pZyH"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"Nff-vKELpZyI"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","import pandas as pd\n","import numpy as np\n","from scipy import stats\n","\n","# Assuming your dataframe is called df and has columns [\"WeekdayName\", \"Sales\"]\n","\n","# Split data into Saturday and Monday\n","sat_sales = data.loc[data[\"WeekdayName\"] == \"Saturday\", \"Sales\"]\n","mon_sales = data.loc[data[\"WeekdayName\"] == \"Monday\", \"Sales\"]\n","\n","# Descriptive statistics\n","n_sat, n_mon = len(sat_sales), len(mon_sales)\n","mean_sat, mean_mon = sat_sales.mean(), mon_sales.mean()\n","sd_sat, sd_mon = sat_sales.std(ddof=1), mon_sales.std(ddof=1)\n","\n","print(\"Saturday: n =\", n_sat, \", mean =\", mean_sat, \", sd =\", sd_sat)\n","print(\"Monday: n =\", n_mon, \", mean =\", mean_mon, \", sd =\", sd_mon)\n","\n","\n","# Welch’s t-test (independent t-test with unequal variances)\n","ttest_res = stats.ttest_ind(sat_sales, mon_sales, equal_var=False)\n","print(\"Welch’s t-test:\", ttest_res)\n","\n","# One-sided p-value (Sat > Mon)\n","t_stat = ttest_res.statistic\n","p_one_sided = ttest_res.pvalue / 2 if t_stat > 0 else 1 - (ttest_res.pvalue / 2)\n","print(\"One-sided p-value (Sat > Mon):\", p_one_sided)\n","\n"],"metadata":{"id":"s6AnJQjtpZyI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"kLW572S8pZyI"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Welch’s t-test (main test) → p-value for testing whether the mean sales differ between Saturday and Monday.\n","\n","Also computed a one-sided p-value to test specifically whether Saturday sales are higher than Monday sales."],"metadata":{"id":"ytWJ8v15pZyI"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"dWbDXHzopZyI"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Welch’s t-test was chosen as the primary test because it compares mean sales between two groups while being robust to unequal variances and unequal sample sizes."],"metadata":{"id":"M99G98V6pZyI"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering & Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation\n","data.isnull().sum()"],"metadata":{"id":"iRsAHk1K0fpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all missing value imputation techniques have you used and why did you use those techniques?"],"metadata":{"id":"7wuGOrhz0itI"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","No missing values are there."],"metadata":{"id":"1ixusLtI0pqI"}},{"cell_type":"markdown","source":["### 2. Handling Outliers"],"metadata":{"id":"id1riN9m0vUs"}},{"cell_type":"code","source":["# Making copy of original data\n","data1=data.copy()"],"metadata":{"id":"p78SRRb4eAVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Handling Outliers & Outlier treatments\n","num_cols=['Sales','Customers','Open','Promo','SchoolHoliday','Year','Month','Day']\n","data1[num_cols].skew()\n"],"metadata":{"id":"M6w2CzZf04JK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1"],"metadata":{"id":"Peo6Z87oUuyQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Outliers of sales\n","mean = data1['Sales'].mean()\n","std = data1['Sales'].std()\n","\n","outliers = data1[(data1['Sales'] < mean - 3*std) |\n","              (data1['Sales'] > mean + 3*std)]\n","print(\"Remaining outliers:\", len(outliers))"],"metadata":{"id":"MpMLVMStg74k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Applying log tranformation\n","data1['Sales_sqrt'] = np.log1p(data1['Sales'])"],"metadata":{"id":"JuD0qLG6fe4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Outlier of Sales_sqrt\n","mean = data1['Sales_sqrt'].mean()\n","std = data1['Sales_sqrt'].std()\n","\n","outliers = data1[(data1['Sales_sqrt'] < mean - 3*std) |\n","              (data1['Sales_sqrt'] > mean + 3*std)]\n","print(\"Remaining outliers:\", len(outliers))"],"metadata":{"id":"VrNnaWQ9jeZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Outliers of customers\n","mean = data1['Customers'].mean()\n","std = data1['Customers'].std()\n","\n","outliers = data1[(data1['Customers'] < mean - 3*std) |\n","              (data1['Customers'] > mean + 3*std)]\n","print(\"Remaining outliers:\", len(outliers))"],"metadata":{"id":"jbhcVuYFgm8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Applying log transformation\n","data1['Customers_sqrt'] = np.log1p(data1['Customers'])"],"metadata":{"id":"Vn1X4_pTj4F1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Outlier of Customers_sqrt\n","mean = data1['Customers_sqrt'].mean()\n","std = data1['Customers_sqrt'].std()\n","\n","outliers = data1[(data1['Customers_sqrt'] < mean - 3*std) |\n","              (data1['Customers_sqrt'] > mean + 3*std)]\n","print(\"Remaining outliers:\", len(outliers))"],"metadata":{"id":"8a1rLg19kQBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#outliers of open\n","mean = data1['Open'].mean()\n","std = data1['Open'].std()\n","\n","outliers = data1[(data1['Open'] < mean - 3*std) |\n","              (data1['Open'] > mean + 3*std)]\n","print(\"Remaining outliers:\", len(outliers))"],"metadata":{"id":"4FjphPwSh12z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#outliers of schoolholiday\n","mean = data1['SchoolHoliday'].mean()\n","std = data1['SchoolHoliday'].std()\n","\n","outliers = data1[(data1['SchoolHoliday'] < mean - 3*std) |\n","              (data1['SchoolHoliday'] > mean + 3*std)]\n","print(\"Remaining outliers:\", len(outliers))"],"metadata":{"id":"B9STQ8GYiRs9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1"],"metadata":{"id":"__zY52VLUJxV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all outlier treatment techniques have you used and why did you use those techniques?"],"metadata":{"id":"578E2V7j08f6"}},{"cell_type":"markdown","source":["Answer Here.                                                          \n","\n","Here I have appleid log and sqrt transformation in Sales and Customers because outliers are present and it is not neccesary that they are not genuine so we should not remove it. We have used transformations."],"metadata":{"id":"uGZz5OrT1HH-"}},{"cell_type":"markdown","source":["### 3. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["#Unique values of stateholiday\n","data1['StateHoliday'].unique()"],"metadata":{"id":"KO11HybGmbPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encode your categorical columns\n","#Ordinal Encoding\n","import pandas as pd\n","\n","\n","# Ensure all values are treated as strings\n","data1['StateHoliday'] = data1['StateHoliday'].astype(str)\n","\n","# Apply Ordinal encoding\n","order = {'0': 0, 'a': 1, 'b': 2, 'c': 3}\n","data1['StateHoliday_ord'] = data1['StateHoliday'].map(order)\n","\n","\n"],"metadata":{"id":"6zp_NHxLpniU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1['StateHoliday_ord'].unique()"],"metadata":{"id":"vJA9VpAVusc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1.to_csv(\"data1.csv\", index=False)"],"metadata":{"id":"4mvBgYzFxXNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1"],"metadata":{"id":"HNxXmw4cxRP0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all categorical encoding techniques have you used & why did you use those techniques?"],"metadata":{"id":"67NQN5KX2AMe"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Here we have done Ordinal encoding of StateHoliday column so that we can remove categorical value by integer value. For other columns no encoding is needed."],"metadata":{"id":"UDaue5h32n_G"}},{"cell_type":"markdown","source":["**4. Feature Selection**"],"metadata":{"id":"F4uWv_kaJ3JJ"}},{"cell_type":"markdown","source":["#### 1. Feature Manipulation"],"metadata":{"id":"C74aWNz2AliB"}},{"cell_type":"code","source":["# Manipulate Features to minimize feature correlation and create new features\n","num_cols = [\"Sales\", \"Customers\", \"Promo\", \"SchoolHoliday\", \"SalesPerCustomer\", \"Year\", \"Open\",\"StateHoliday_ord\"]\n","corr = data[num_cols].corr()\n","plt.figure(figsize=(6,4))\n","sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\")\n","plt.title(\"Correlation heatmap\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"h1qC4yhBApWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","\n","# Step 1 — keep only numeric columns for correlation analysis\n","numeric_data1 = data1.select_dtypes(include=[np.number])\n","\n","# Step 2 — compute correlation matrix\n","corr_matrix = numeric_data1.corr().abs()   # absolute correlations\n","\n","# Step 3 — keep only upper triangle (avoid duplicate pairs)\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","\n","# Step 4 — find columns to drop\n","threshold = 0.90   # you can change to 0.85 or 0.95\n","to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n","\n","print(\"Highly correlated features to drop:\", to_drop)\n","\n","# Step 5 — drop them from the dataset\n","data1_reduced = data1.drop(columns=to_drop)\n"],"metadata":{"id":"Y4EoSKc6pYLu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Feature Selection"],"metadata":{"id":"2DejudWSA-a0"}},{"cell_type":"code","source":["# Select your features wisely to avoid overfitting\n","data1 = data1.drop(columns=['Date','Store'])\n"],"metadata":{"id":"YLhe8UmaBCEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Select Columns which are not required\n","data1 = data1.drop(columns=['Sales','Customers','WeekOfYear','WeekdayName','SalesPerCustomer'])\n"],"metadata":{"id":"46QqCf8upymi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1"],"metadata":{"id":"SKQU1xt0qy3b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all feature selection methods have you used  and why?"],"metadata":{"id":"pEMng2IbBLp7"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I have found the correlation between the numerical features and dropped those columns which are not required and having high correlation value."],"metadata":{"id":"rb2Lh6Z8BgGs"}},{"cell_type":"markdown","source":["##### Which all features you found important and why?"],"metadata":{"id":"rAdphbQ9Bhjc"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Features which are important for making the model are DayOfWeek, Open,\tPromo, StateHoliday,\tSchoolHoliday,\tStateHoliday_ord,\tYear,\tMonth,\tDay,\tSales_sqrt,\tCustomers_sqrt."],"metadata":{"id":"fGgaEstsBnaf"}},{"cell_type":"markdown","source":["### 5. Data Transformation"],"metadata":{"id":"TNVZ9zx19K6k"}},{"cell_type":"markdown","source":["#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"],"metadata":{"id":"nqoHp30x9hH9"}},{"cell_type":"code","source":["# Transform Your data"],"metadata":{"id":"I6quWQ1T9rtH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. Data Scaling"],"metadata":{"id":"rMDnDkt2B6du"}},{"cell_type":"code","source":["# Scaling your data\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","cols_to_scale = [\"Customers_sqrt\", \"Sales_sqrt\"]\n","scaler = StandardScaler()\n","\n","# Fit & transform only the selected columns\n","data1[cols_to_scale] = scaler.fit_transform(data1[cols_to_scale])\n","\n","# Check result\n","print(data1[cols_to_scale].head())"],"metadata":{"id":"dL9LWpySC6x_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which method have you used to scale you data and why?"],"metadata":{"id":"yiiVWRdJDDil"}},{"cell_type":"markdown","source":["You have used the StandardScaler method. You used StandardScaler (Z-score scaling) because it standardizes the data, making it suitable for models that assume normally distributed features or require equal weighting across variables."],"metadata":{"id":"_o0FG2iwMrtg"}},{"cell_type":"markdown","source":["### 7. Dimesionality Reduction"],"metadata":{"id":"1UUpS68QDMuG"}},{"cell_type":"markdown","source":["##### Do you think that dimensionality reduction is needed? Explain Why?"],"metadata":{"id":"kexQrXU-DjzY"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"GGRlBsSGDtTQ"}},{"cell_type":"code","source":["# DImensionality Reduction (If needed)"],"metadata":{"id":"kQfvxBBHDvCa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"],"metadata":{"id":"T5CmagL3EC8N"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"ZKr75IDuEM7t"}},{"cell_type":"markdown","source":["### 8. Data Splitting"],"metadata":{"id":"BhH2vgX9EjGr"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report, f1_score\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.over_sampling import SMOTE\n","from imblearn.pipeline import Pipeline as ImbPipeline\n","import shap\n","import joblib\n","from imblearn.combine import SMOTEENN"],"metadata":{"id":"wBo9tmW_u8D-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split your data to train and test. Choose Splitting ratio wisely.\n","data1= pd.get_dummies(data1, drop_first=True)\n","\n","# Features & Target\n","X = data1.drop(\"Sales_sqrt\", axis=1)\n","y = data1[\"Sales_sqrt\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"0CTyd2UwEyNM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What data splitting ratio have you used and why?"],"metadata":{"id":"qjKvONjwE8ra"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Train data I have taken 80 percent and test data I have taken 20 percent. So  that we can train our model on maximum data and then predict the values on 20 percent of data."],"metadata":{"id":"Y2lJ8cobFDb_"}},{"cell_type":"markdown","source":["### 9. Handling Imbalanced Dataset"],"metadata":{"id":"P1XJ9OREExlT"}},{"cell_type":"markdown","source":["##### Do you think the dataset is imbalanced? Explain Why."],"metadata":{"id":"VFOzZv6IFROw"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"GeKDIv7pFgcC"}},{"cell_type":"code","source":["# Handling Imbalanced Dataset (If needed)"],"metadata":{"id":"nQsRhhZLFiDs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"],"metadata":{"id":"TIqpNgepFxVj"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"qbet1HwdGDTz"}},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["### ML Model - 1"],"metadata":{"id":"OB4l2ZhMeS1U"}},{"cell_type":"code","source":["# ML Model - 1 Implementation\n","from sklearn.linear_model import LinearRegression\n","# Fit the Algorithm\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Predict on the model\n","y_pred = model.predict(X_test)"],"metadata":{"id":"7ebyywQieS1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"code","source":["\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","\n","#  Calculate metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","\n","# Adjusted R²\n","n = len(y_test)   # number of samples\n","p = X_test.shape[1]  # number of predictors\n","adj_r2 = 1 - (1-r2) * (n-1)/(n-p-1)\n","\n","# MAPE (handle division by zero safely)\n","mask = y_test != 0\n","mape = np.mean(np.abs((y_test[mask] - y_pred[mask]) / y_test[mask])) * 100\n","\n","\n","\n","\n","print(\"Model Evaluation Metrics:\")\n","print(f\"MAE  : {mae:.2f}\")\n","print(f\"MSE  : {mse:.2f}\")\n","print(f\"RMSE : {rmse:.2f}\")\n","print(f\"R²   : {r2:.4f}\")\n","print(f\"Adjusted R²: {adj_r2:.4f}\")\n","print(f\"MAPE : {mape:.2f}%\")\n"],"metadata":{"id":"rqD5ZohzfxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"4qY1EAkEfxKe"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","\n","# Fit the Algorithm\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","data_sample = data1.sample(frac=0.1, random_state=42)\n","X = data_sample.drop(\"Sales_sqrt\", axis=1)\n","y = data_sample[\"Sales_sqrt\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [4,6],\n","    'max_features': ['sqrt', 'log2']\n","}\n","\n","rf = RandomForestRegressor(random_state=42)\n","grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n","grid_search.fit(X_train, y_train)\n","# Predict on the model\n","best_model = grid_search.best_estimator_\n","y_pred = best_model.predict(X_test)\n","\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","\n","# Adjusted R²\n","n = len(y_test)   # number of samples\n","p = X_test.shape[1]  # number of predictors\n","adj_r2 = 1 - (1-r2) * (n-1)/(n-p-1)\n","\n","# MAPE (handle division by zero safely)\n","mask = y_test != 0\n","mape = np.mean(np.abs((y_test[mask] - y_pred[mask]) / y_test[mask])) * 100\n","\n","\n","\n","\n","print(\"Model Evaluation Metrics:\")\n","print(f\"MAE  : {mae:.2f}\")\n","print(f\"MSE  : {mse:.2f}\")\n","print(f\"RMSE : {rmse:.2f}\")\n","print(f\"R²   : {r2:.4f}\")\n","print(f\"Adjusted R²: {adj_r2:.4f}\")\n","print(f\"MAPE : {mape:.2f}%\")\n","\n"],"metadata":{"id":"Dy61ujd6fxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"PiV4Ypx8fxKe"}},{"cell_type":"markdown","source":["Answer Here.\n","I have used Grid Search Cross-Validation (GridSearchCV) for hyperparameter optimization.\n","GridSearchCV systematically tries all possible combinations of hyperparameters provided in the param_grid."],"metadata":{"id":"negyGRa7fxKf"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"TfvqoZmBfxKf"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Initially, the RandomForest/XGBoost model achieved very high accuracy with:\n","\n","MAE = 0.04, RMSE = 0.06, R² = 0.9968, MAPE = 12.86%.\n","\n","These results indicated excellent fit on the chosen train-test split.\n","\n","After applying cross-validation and hyperparameter tuning, the metrics slightly changed to:\n","\n","MAE = 0.05, RMSE = 0.07, R² = 0.9944, MAPE = 18.79%.\n","\n","Although the error values increased marginally, the model remains highly accurate and generalizable. The slight reduction in performance is expected because cross-validation provides a more realistic estimate of model performance on unseen data, reducing the risk of overfitting.\n","\n","Thus, the final tuned model is considered robust and reliable, with an R² above 0.99 and MAPE under 20%, which are acceptable for sales forecasting tasks in retail."],"metadata":{"id":"OaLui8CcfxKf"}},{"cell_type":"markdown","source":["### ML Model - 2"],"metadata":{"id":"dJ2tPlVmpsJ0"}},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"JWYfwnehpsJ1"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","# Visualizing evaluation Metric Score chart\n","# Initialize XGBoost Regressor\n","xgb_model = xgb.XGBRegressor(\n","    n_estimators=500,\n","    max_depth=6,\n","    learning_rate=0.1,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    random_state=42\n",")\n","\n","# Fit the model\n","xgb_model.fit(X_train, y_train)\n","# Predict on the model\n","y_pred = xgb_model.predict(X_test)\n","\n","\n","mask = y_test > 0  # safe MAPE\n","mae = mean_absolute_error(y_test[mask], y_pred[mask])\n","mse = mean_squared_error(y_test[mask], y_pred[mask])\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test[mask], y_pred[mask])\n","n = len(y_test[mask])\n","p = X_test.shape[1]\n","adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n","mape = np.mean(np.abs((y_test[mask] - y_pred[mask]) / y_test[mask])) * 100\n","\n","print(\"XGBoost Model Performance:\")\n","print(f\"MAE  : {mae:.2f}\")\n","print(f\"MSE  : {mse:.2f}\")\n","print(f\"RMSE : {rmse:.2f}\")\n","print(f\"R²   : {r2:.4f}\")\n","print(f\"Adjusted R²: {adj_r2:.4f}\")\n","print(f\"MAPE : {mape:.2f}%\")\n","\n"],"metadata":{"id":"yEl-hgQWpsJ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"-jK_YjpMpsJ2"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","import xgboost as xgb\n","\n","\n","data_sample = data1.sample(frac=0.1, random_state=42)\n","X = data_sample.drop(\"Sales_sqrt\", axis=1)\n","y = data_sample[\"Sales_sqrt\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","\n","# Define parameter distribution\n","param_dist = {\n","    \"n_estimators\": [100, 200],\n","    \"max_depth\": [3, 5, 7],\n","    \"learning_rate\": [0.01, 0.05, 0.1],\n","    \"subsample\": [0.6, 0.7, 0.8],\n","    \"colsample_bytree\": [0.6, 0.7]\n","}\n","\n","# Corrected: Pass an instance of XGBRegressor to the estimator\n","xgb_model = xgb.XGBRegressor(random_state=42)\n","\n","random_search = RandomizedSearchCV(\n","    estimator=xgb_model,  # Corrected this line\n","    param_distributions=param_dist,\n","    n_iter=20,  # Number of random combinations\n","    scoring=\"r2\",\n","    cv=3,\n","    verbose=2,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","\n","random_search.fit(X_train, y_train)\n","\n","print(\"Best Parameters:\", random_search.best_params_)\n","\n","# Predict\n","y_pred = random_search.predict(X_test)\n","\n","# Evaluate\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n","\n","print(f\"MAE  : {mae:.2f}\")\n","print(f\"MSE  : {mse:.2f}\")\n","print(f\"RMSE : {rmse:.2f}\")\n","print(f\"R²   : {r2:.4f}\")\n","print(f\"MAPE : {mape:.2f}%\")"],"metadata":{"id":"Dn0EOfS6psJ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"HAih1iBOpsJ2"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","I used RandomizedSearchCV (Randomized Search with Cross-Validation) for hyperparameter optimization.\n","More efficient when the hyperparameter space is large, since it avoids testing every possible combination."],"metadata":{"id":"9kBgjYcdpsJ2"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"zVGeBEFhpsJ2"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Yes — improvement can be checked by comparing the evaluation metrics from the RandomizedSearchCV (XGBoost model) .\n","Lower MAE & RMSE → better prediction accuracy\n","Higher R² → better variance explained by the model\n","Lower MAPE → more reliable forecasts"],"metadata":{"id":"74yRdG6UpsJ3"}},{"cell_type":"markdown","source":["#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."],"metadata":{"id":"bmKjuQ-FpsJ3"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Evaluation Metrics & Business Impact\n","\n","MAE (Mean Absolute Error): Shows average prediction error. Lower MAE → better accuracy → helps reduce under/overstocking.\n","\n","MSE (Mean Squared Error): Penalizes large errors more. Lower MSE → avoids big mistakes → better budgeting & logistics.\n","\n","RMSE (Root Mean Squared Error): Typical prediction error in sales units. Lower RMSE → more reliable forecasts → builds trust in planning.\n","\n","R² (Coefficient of Determination): Explains how much variance in sales is captured. Higher R² → model captures key drivers → stronger insights.\n","\n","MAPE (Mean Absolute Percentage Error): Shows error in % terms. Lower MAPE → more business-friendly → useful for executives in financial planning."],"metadata":{"id":"BDKtOrBQpsJ3"}},{"cell_type":"markdown","source":["### ML Model - 3"],"metadata":{"id":"Fze-IPXLpx6K"}},{"cell_type":"code","source":["# ML Model - 3 Implementation\n","\n","# Fit the Algorithm\n","rf_model = RandomForestRegressor(\n","    n_estimators=200,   # number of trees\n","    max_depth=20,       # depth of trees\n","    random_state=42,\n","    n_jobs=-1\n",")\n","\n","# Fit model\n","rf_model.fit(X_train, y_train)\n","\n","# Predict\n","y_pred = rf_model.predict(X_test)\n","\n","# Safe MAPE (exclude zero-sales)\n","mask = y_test > 0\n","mae = mean_absolute_error(y_test[mask], y_pred[mask])\n","mse = mean_squared_error(y_test[mask], y_pred[mask])\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test[mask], y_pred[mask])\n","n = len(y_test[mask])\n","p = X_test.shape[1]\n","adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n","mape = np.mean(np.abs((y_test[mask] - y_pred[mask]) / y_test[mask])) * 100\n","\n","print(\"Random Forest Performance:\")\n","print(f\"MAE  : {mae:.2f}\")\n","print(f\"MSE  : {mse:.2f}\")\n","print(f\"RMSE : {rmse:.2f}\")\n","print(f\"R²   : {r2:.4f}\")\n","print(f\"Adjusted R²: {adj_r2:.4f}\")\n","print(f\"MAPE : {mape:.2f}%\")\n","\n"],"metadata":{"id":"FFrSXAtrpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"7AN1z2sKpx6M"}},{"cell_type":"markdown","source":["# Visualizing evaluation Metric Score chart\n","\n","I have used Random Forest Regressor model.\n","An ensemble of decision trees that predicts continuous values.\n","Handles non-linear patterns, outliers and multiple features well.\n","\n","Performance Metrics:\n","\n","Metric\tValue\tMeaning\n","MAE-0.05 - Small average prediction error\n","RMSE-0.06\t- Low overall error magnitude\n","R²-0.7672 - Explains ~77% of sales variance\n","Adj R²-0.7670\t- Features are relevant, low overfitting\n","MAPE-12.60%\t- Predictions deviate ~13% on average"],"metadata":{"id":"5L2IyK2M4-9E"}},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"9PIHJqyupx6M"}},{"cell_type":"code","source":["# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","data_sample = data1.sample(frac=0.1, random_state=42)\n","X = data_sample.drop(\"Sales_sqrt\", axis=1)\n","y = data_sample[\"Sales_sqrt\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Parameter distribution\n","param_dist = {\n","    \"n_estimators\": [100, 200, 500],\n","    \"max_depth\": [None, 10, 20, 30],\n","    \"min_samples_split\": [2, 5, 10],\n","    \"min_samples_leaf\": [1, 2, 4],\n","    \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n","}\n","\n","# RandomizedSearchCV\n","random_search = RandomizedSearchCV(\n","    estimator=rf,\n","    param_distributions=param_dist,\n","    n_iter=20,   # Number of random combinations\n","    cv=3,\n","    verbose=2,\n","    random_state=42,\n","    n_jobs=-1,\n","    scoring=\"r2\"\n",")\n","\n","random_search.fit(X_train, y_train)\n","\n","\n","# Best model\n","best_rf = random_search.best_estimator_\n","\n","# Predict\n","y_pred = best_rf.predict(X_test)\n","\n","# Evaluate\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n","\n","print(f\"MAE  : {mae:.2f}\")\n","print(f\"MSE  : {mse:.2f}\")\n","print(f\"RMSE : {rmse:.2f}\")\n","print(f\"R²   : {r2:.4f}\")\n","print(f\"MAPE : {mape:.2f}%\")\n"],"metadata":{"id":"eSVXuaSKpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"_-qAgymDpx6N"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","We have used here RandomizedSearchCV. Efficiently searches over a wide range of hyperparameter combinations randomly instead of exhaustively."],"metadata":{"id":"lQMffxkwpx6N"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"Z-hykwinpx6N"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","RandomizedSearchCV improved model performance slightly, reducing prediction errors (MAE, RMSE, MAPE) and increasing R².\n","\n","Business Impact: Predictions are more reliable, leading to better sales forecasting and inventory management."],"metadata":{"id":"MzVzZC6opx6N"}},{"cell_type":"markdown","source":["### 1. Which Evaluation metrics did you consider for a positive business impact and why?"],"metadata":{"id":"h_CCil-SKHpo"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Evaluation metric that is considered for positive impact is MAE, RMSE,R2, MAPE. Because MAE measures average actual deviation from actual sales, RMSE penalize large error more heavily, R2 indicate how much variance in sales is explained by the model, MAPE expresses prediction error as percentage making it intuitive for stakeholders."],"metadata":{"id":"jHVz9hHDKFms"}},{"cell_type":"markdown","source":["### 2. Which ML model did you choose from the above created models as your final prediction model and why?"],"metadata":{"id":"cBFFvTBNJzUa"}},{"cell_type":"markdown","source":["Answer\n","\n","Final Chosen Model is Random Forest Regressor (with hyperparameter tuning using RandomizedSearchCV). I chose the tuned Random Forest model because it balances strong predictive power with stability, interpretability and clear business value.\n","\n"],"metadata":{"id":"6ksF5Q1LKTVm"}},{"cell_type":"markdown","source":["### 3. Explain the model which you have used and the feature importance using any model explainability tool?"],"metadata":{"id":"HvGl1hHyA_VK"}},{"cell_type":"markdown","source":["Answer Here.\n","\n","Model Used: Random Forest Regressor (tuned with RandomizedSearchCV)\n","\n","Feature Importance (Explainability):\n","\n","Used Random Forest’s built-in feature importance and SHAP.\n","\n","Key drivers found: Promo, DayOfWeek, SchoolHoliday and Customers.\n","\n","Promo has the highest impact on sales.\n","\n"],"metadata":{"id":"YnvVTiIxBL-C"}},{"cell_type":"markdown","source":["## ***8.*** ***Future Work (Optional)***"],"metadata":{"id":"EyNgTHvd2WFk"}},{"cell_type":"markdown","source":["### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"],"metadata":{"id":"KH5McJBi2d8v"}},{"cell_type":"code","source":["# Save the File"],"metadata":{"id":"bQIANRl32f4J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"],"metadata":{"id":"iW_Lq9qf2h6X"}},{"cell_type":"code","source":["# Load the File and predict unseen data."],"metadata":{"id":"oEXk9ydD2nVC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"],"metadata":{"id":"-Kee-DAl2viO"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["Write the conclusion here.\n","\n","1. Sales are strongly influenced by the number of Customers and Promotions. Stores with active promotions and higher footfall see significantly higher sales.\n","\n","2. Day of the Week plays an important role. Sales patterns vary across weekdays vs. weekends, showing the need for demand forecasting by day.\n","\n","3. Holidays (SchoolHoliday & StateHoliday) also impact sales. These special days create noticeable fluctuations—some stores see demand drop, while others spike.\n","\n","4. Store Open status is a direct determinant. If a store is closed, sales drop to zero, reinforcing its role as a control variable."],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}